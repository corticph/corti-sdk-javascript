/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../mock-server/MockServerPool.js";
import { CortiClient } from "../../src/Client";

describe("Transcripts", () => {
    test("create", async () => {
        const server = mockServerPool.createServer();
        const client = new CortiClient({ token: "test", tenantName: "test", environment: server.baseUrl });
        const rawRequestBody = {
            recordingId: "f47ac10b-58cc-4372-a567-0e02b2c3d479",
            primaryLanguage: "en",
            modelName: "premier",
        };
        const rawResponseBody = {
            id: "f47ac10b-58cc-4372-a567-0e02b2c3d479",
            metadata: { participantsRoles: [{}] },
            transcripts: [{ channel: 1, participant: 1, speakerId: 1, text: "text", start: 1, end: 1 }],
            usageInfo: { creditsConsumed: 1.1 },
        };
        server
            .mockEndpoint()
            .post("/interactions/f47ac10b-58cc-4372-a567-0e02b2c3d479/transcripts/")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.transcripts.create("f47ac10b-58cc-4372-a567-0e02b2c3d479", {
            recordingId: "f47ac10b-58cc-4372-a567-0e02b2c3d479",
            primaryLanguage: "en",
            modelName: "premier",
        });
        expect(response).toEqual({
            id: "f47ac10b-58cc-4372-a567-0e02b2c3d479",
            metadata: {
                participantsRoles: [{}],
            },
            transcripts: [
                {
                    channel: 1,
                    participant: 1,
                    speakerId: 1,
                    text: "text",
                    start: 1,
                    end: 1,
                },
            ],
            usageInfo: {
                creditsConsumed: 1.1,
            },
        });
    });

    test("get", async () => {
        const server = mockServerPool.createServer();
        const client = new CortiClient({ token: "test", tenantName: "test", environment: server.baseUrl });

        const rawResponseBody = {
            id: "f47ac10b-58cc-4372-a567-0e02b2c3d479",
            metadata: { participantsRoles: [{}] },
            transcripts: [{ channel: 1, participant: 1, speakerId: 1, text: "text", start: 1, end: 1 }],
            usageInfo: { creditsConsumed: 1.1 },
        };
        server
            .mockEndpoint()
            .get("/interactions/f47ac10b-58cc-4372-a567-0e02b2c3d479/transcripts/f47ac10b-58cc-4372-a567-0e02b2c3d479")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.transcripts.get(
            "f47ac10b-58cc-4372-a567-0e02b2c3d479",
            "f47ac10b-58cc-4372-a567-0e02b2c3d479",
        );
        expect(response).toEqual({
            id: "f47ac10b-58cc-4372-a567-0e02b2c3d479",
            metadata: {
                participantsRoles: [{}],
            },
            transcripts: [
                {
                    channel: 1,
                    participant: 1,
                    speakerId: 1,
                    text: "text",
                    start: 1,
                    end: 1,
                },
            ],
            usageInfo: {
                creditsConsumed: 1.1,
            },
        });
    });

    test("delete", async () => {
        const server = mockServerPool.createServer();
        const client = new CortiClient({ token: "test", tenantName: "test", environment: server.baseUrl });

        server
            .mockEndpoint()
            .delete(
                "/interactions/f47ac10b-58cc-4372-a567-0e02b2c3d479/transcripts/f47ac10b-58cc-4372-a567-0e02b2c3d479",
            )
            .respondWith()
            .statusCode(200)
            .build();

        const response = await client.transcripts.delete(
            "f47ac10b-58cc-4372-a567-0e02b2c3d479",
            "f47ac10b-58cc-4372-a567-0e02b2c3d479",
        );
        expect(response).toEqual(undefined);
    });
});
